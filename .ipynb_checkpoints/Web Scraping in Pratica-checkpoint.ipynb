{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "import networkx as nx\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping\n",
    "Con il termine **web scraping** si intende l'estrazione di dati da risorse Web attraverso una serie di procedure che non invocano le API. Essenzialmente si richiede una risorsa ad un web server per estrarne le informazioni necessarie.\n",
    "\n",
    "I web browser rappresentano uno dei principali strumenti di accesso alle risorse Web, tuttavia l'esigenza di disporre le informazioni rendendole facilmente leggibili agli utenti li rende poco adatti per l'estrazione e il processamento di grandi quantità di dati. I web scraper sopperiscono a queste limitazioni.\n",
    "\n",
    "Il web scraping sosituisce le API quando:\n",
    "* non esistono\n",
    "* i limiti sul volume di richieste sono troppo vincolanti per l'applicazione che si vuole sviluppare\n",
    "\n",
    "## Primi passi\n",
    "Lo sviluppo di un web scraper richiede una buona conoscenza:\n",
    "- HTTP -HTML e Javascript (non strettamente necessario). Conoscenze e dettagli che il web browser cela all'utente finale.\n",
    "\n",
    "Uno dei primi passi nel web scraping è inviare richieste HTTP ad un web server per poter accedere alla risorsa desiderata.\n",
    "\n",
    "Come strumento per gestire le richieste/risposte HTTP utilizzeremo il modulo **requests**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Installazione di un modulo)\n",
    "1. Aprire un prompt dei comandi\n",
    "2. Spostarsi nella directory Users\\<username>\\Anaconda3\\Script\n",
    "3. Digitare il comando pip install requests. In generale il comando è pip install **nome_modulo**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attraverso questo modulo possiamo inviare una richiesta GET ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "risposta = requests.get('http://pythonscraping.com/pages/page1.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Possiamo accedere al contenuto della risorsa attraverso l'attributo **content**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "risposta.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "risposta.headers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il contenuto corrisponde al codice HTML della pagina/risorsa richiesta.\n",
    "\n",
    "## Gestione minimale degli errori\n",
    "In caso di problemi di rete, il modulo solleva un'eccezione **ConnectionError**, mentre in caso di connection timeout viene sollevata l'eccezione **Timeout**. In generale tutte le eccezioni sollevate da requests ereditano dall'eccezione **requests.exceptions.RequestException**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    risposta = requests.get('http://pythonscraping.com/pages/page1.html')\n",
    "except requests.exceptions.RequestException as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Beautiful Soup\n",
    "BS è un modulo che permette di estrarre informazioni da una pagina HTML cercando di correggere HTML malformato e trasformando il codice HTML in una struttura XML facilmente navigabile (ricerca e attraversamento - traversal).\n",
    "\n",
    "L'oggetto BeautifulSoup rappresenta il punto d'accesso alla risorsa HTML.\n",
    "\n",
    "Per installare BeautifulSoup utilizzo il comando **pip install beautifulsoup4**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bsObj = BeautifulSoup(risposta.content,'lxml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La pagina HTML (risposta.content) ha la seguente struttura\n",
    "<img src='tree_html.jpg'>\n",
    "Di conseguenza posso accedere ai nodi dell'albero utilizzando la notazione puntata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(bsObj.html.body.h1)\n",
    "print(bsObj.body.h1)\n",
    "print(bsObj.h1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping Applicato: WeHeartIt\n",
    "WeHeartIt è un social network per molti aspetti molto simile a Instagram o Pinterest che non mette ad disposizione una API per poter ottenere informazioni sugli utenti, immagini postate e altri elementi che caratterizzano la piattaforma. \n",
    "\n",
    "Per questi motivi lo utilizzeremo che caso di studio per mostrare alcuni metodi di estrazione delle informazioni.\n",
    "\n",
    "## Login e form\n",
    "Form e login sono ormai parte integrate di qualsiasi piattaforma social in quanto permettono di autenticare l'utente e offrire un servizio personalizzato. In più alcune funzionalità sono rese disponibili se e solo se l'utente è loggato.\n",
    "\n",
    "Dal punto di vista HTML, un modulo di login corrisponde ad un form. Un form permette all'utente di inviare una richiesta POST al web server.\n",
    "\n",
    "In questa parte replicheremo il processo di login a WHI utilizzando il modulo requests.\n",
    "La pagina di login è disponibile all'indirizzo weheartit.com/login \n",
    "<img src='login.png'>\n",
    "Attraverso la funzione 'Ispeziona elemento' messa a disposizione da Chrome possiamo analizzare il codice HTML corrispondente al form di login. In particolare il seguente codice è tipico dei form HTML\n",
    "\n",
    "``` html\n",
    "<form accept-charset=\"UTF-8\" action=\"https://weheartit.com/login/authenticate\" class=\"new_user\" id=\"new_user\" method=\"post\">\n",
    "    <div style=\"display:none\">\n",
    "        <input name=\"utf8\" type=\"hidden\" value=\"✓\">\n",
    "        <input name=\"authenticity_token\" type=\"hidden\" value=\"7nob+s3tKKbYNHEUFqKkzM1kp5g3ykl2uVtAC2/hLJG6uEF4QkxEoGHBWIFY7sTnMVMWOldZZmglLEKLdP73Rg==\">\n",
    "    </div>\n",
    "    <input class=\"btn-large input-block js-empty\" id=\"user_email_or_username\" name=\"user[email]\" placeholder=\"Indirizzo e-mail o nome utente\" type=\"text\">\n",
    "    <input class=\"btn-large input-block js-empty\" id=\"user_password_login\" name=\"user[password]\" placeholder=\"Password\" type=\"password\">\n",
    "    <input type=\"submit\" value=\"Seguente\" class=\"btn btn-block btn-large bg-primary sign_up_button disabled\" disabled=\"disabled\">\n",
    "</form>\n",
    "```\n",
    "Gli attributi fondamentali per il tag form sono:\n",
    "- **action**: indica l'url a cui verranno inviati i dati del form\n",
    "- **method**: indica il metodo http con cui inviare la richiesta\n",
    "Il tag input indica quali campi verranno inviati all'url specificato dall'attributo action. Ogni input ha un nome del campo (valore associato all'attributo _name_), mentre il valore dipende dal tipo di campo.\n",
    "\n",
    "Cliccando il pulsante 'Seguente' il contenuto del form viene inviato alla risorsa tramite una richiesta http POST:\n",
    "\n",
    "E' possibile ispezionare la richiesta inviata, attraverso la console di Chrome (CTRL+SHIFT+I). Le richieste HTTP sono visibili nel tab 'Network'.\n",
    "\n",
    "Nel nostro caso la richiesta HTTP è la seguente (solo informazioni essenziali):\n",
    "```\n",
    "POST /login/authenticate HTTP/1.1\n",
    "Host: weheartit.com\n",
    "Connection: keep-alive\n",
    "Content-Length: 149\n",
    "Cache-Control: max-age=0\n",
    "Origin: http://weheartit.com\n",
    "User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/57.0.2987.133 Safari/537.36\n",
    "Content-Type: application/x-www-form-urlencoded\n",
    "Referer: http://weheartit.com/login\n",
    "Accept-Encoding: gzip, deflate, br\n",
    "Accept-Language: it-IT,it;q=0.8,en-US;q=0.6,en;q=0.4\n",
    "\n",
    "utf8:✓\n",
    "authenticity_token:7nob+s3tKKbYNHEUFqKkzM1kp5g3ykl2uVtAC2/hLJG6uEF4QkxEoGHBWIFY7sTnMVMWOldZZmglLEKLdP73Rg==\n",
    "user[email]:somenilab@gmail.com\n",
    "user[password]:SomeniLab\n",
    "```\n",
    "\n",
    "Dato il codice HTML del form è possibile, quindi, ricostruire la richiesta http da inviare.\n",
    "\n",
    "Proviamo a loggarci in WHI..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parametri = {'user[email]':'somenilab@gmail.com',\n",
    "             'user[password]':'SomeniLab',\n",
    "            'authenticity_token':'ugPJ3bSDakNaFzEbOdysnkwp8y7V8syYAkaa0Fn/Ek1Wf/Ra2XXR93D4VqWfSzjIgHMTNhClqkr4gRCWXyW2pQ=='}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rispostaLoginWHI = requests.post('https://weheartit.com/login/authenticate',data=parametri,allow_redirects=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per mantenere lo stato di 'utente loggato' le varie webapp utilizzano i cookies per mantenere lo 'stato' tra diverse richieste HTTP. I siti utilizzano i cookies per controllare l'identità dell'utente loggato. \n",
    "\n",
    "Dal punto di vista del web scraper, per mantenere un utente loggato esso deve gestire i cookies. Il modulo requests agevola la gestione dei cookies...\n",
    "\n",
    "Vediamo i cookie inviati da WHI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rispostaLoginWHI.cookies.get_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per verificare che i cookie vengano settati correttamente possiamo richiedere la pagina delle 'impostazioni' relative all'utente loggato e cercare la stringa 'somenilab'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rispostaSettings  = requests.get('https://weheartit.com/settings', cookies = rispostaLoginWHI.cookies)\n",
    "str(rispostaSettings.content).find('somenilab')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### La classe Session di requests\n",
    "Requests mette a disposizione la classe Session per mantenere la persistenza di una sessione HTML. La classe gestisce i cookie e ci evita di passare i cookies come argomento ad ogni richiesta GET o POST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "whi_session = requests.session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vediamo come risolvere il problema precedente attraverso richieste inviate mediante la classe Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "whi_session.post('https://weheartit.com/login/authenticate',data=parametri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "whi_session.cookies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rispostaSettings  = whi_session.get('https://weheartit.com/settings')\n",
    "str(rispostaSettings.content).find('somenilab')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Immagini popolari il 14/02/2018\n",
    "In WHI è possibile visualizzare le immagini più apprezzate ('numero di heart') in un giorno specifico. In questo esempio vogliamo ottenere le immagini popolari il 14/02/2018.\n",
    "\n",
    "La risorsa da richiedere è **/popular_images/2018/02/14** e la pagina restituita è la seguente:\n",
    "<img src='most_popular.png'>\n",
    "Se ispezioniamo il codice di ogni elemento che racchiude un'immagine otteniamo il seguente codice HTML:\n",
    "``` HTML\n",
    "<div class=\"entry grid-item\" data-actionable=\"false\" data-context-user-id=\"35809162\" data-context=\"popular_images\" data-entry-group-id=\"107512524\" data-entry-id=\"278465817\" data-page-number=\"1\" data-promoted=\"false\" data-uploader-username=\"the_night_skies\">\n",
    "    <div class=\"no-padding\">\n",
    "        <div class=\"entry-preview \">\n",
    "            <a class=\"js-entry-detail-link\" href=\"/entry/278465817/popular_images/2017/02/16\" tabindex=\"-1\">\n",
    "              <img alt=\"food\" class=\"entry-thumbnail\" height=\"250\" src=\"http://data.whicdn.com/images/278465817/superthumb.webp\" width=\"300\">  \n",
    "            </a>\n",
    "            <div class=\"entry-hover\">\n",
    "                <div class=\"user-preview grid-flex \">\n",
    "                    <div class=\"col\">\n",
    "                          <a class=\"avatar-container avatar-small\" href=\"/the_night_skies\"><img alt=\"་ Aᴅᴠᴇɴᴛᴜʀᴇ ་\" class=\"avatar\" src=\"http://data.whicdn.com/avatars/35809162/thumb.webp?1488568625\" title=\"་ Aᴅᴠᴇɴᴛᴜʀᴇ ་\"><span class=\"avatar-badge badge-heartist\"></span>\n",
    "                          </a>\n",
    "                    </div>\n",
    "                    <div class=\"col span-12\">\n",
    "                        <span class=\"text-overflow-parent\">\n",
    "                              <span class=\"text-overflow\">\n",
    "                                <a href=\"/the_night_skies\">\n",
    "                                  <span class=\"text-big\">་ Aᴅᴠᴇɴᴛᴜʀᴇ ་</span>\n",
    "                                </a><br>\n",
    "                                <small><abbr class=\"timeago\" title=\"2 mesi fa\">2 mesi fa</abbr></small>\n",
    "                                &nbsp;\n",
    "                              </span>\n",
    "                        </span>\n",
    "                    </div>\n",
    "                    <div class=\"col\">\n",
    "                          <a href=\"javascript:void(0);\" class=\"js-follow-button btn text-primary btn-small\" data-user-id=\"35809162\" data-username=\"the_night_skies\" data-collection-count=\"0\">Segui</a>\n",
    "                    </div>\n",
    "                </div> \n",
    "                <a href=\"/entry/278465817\" class=\"btn-heart btn btn-heart-circle js-heart-button\" data-tiny-thumb=\"http://data.whicdn.com/images/278465817/tiny.webp\" data-entry-id=\"278465817\" data-hearter-username=\"the_night_skies\">\n",
    "  <i class=\"icon icon-heart icon-primary  \"></i>\n",
    "                </a>\n",
    "                <div class=\"entry-actions\">\n",
    "                    <div class=\"grid-flex js-entry-hover-collections-select\" style=\"display:none\" data-entry-id=\"278465817\">\n",
    "                        <div class=\"col\">\n",
    "                            <a href=\"#\" class=\"btn btn-block btn-dropdown text-primary text-left js-add-to-collection\" data-entry-id=\"278465817\">\n",
    "                                <i class=\"icon icon-collection icon-primary\"></i> &nbsp;&nbsp;\n",
    "                                Aggiungi alle collezioni\n",
    "                            </a>\n",
    "                        </div>\n",
    "                        <a href=\"#\" class=\"col hide-sm js-hide-entry-hover-collections-select\" data-entry-id=\"278465817\"> &nbsp;&nbsp;\n",
    "                              <i class=\"icon icon-medium icon-white icon-more\"></i>\n",
    "                        </a>\n",
    "                    </div>\n",
    "                    <div class=\"grid-flex text-center js-entry-hover-actions\" data-entry-id=\"278465817\">        \n",
    "                        <a href=\"javascript:void(0)\" class=\"js-add-to-collection col\" data-entry-id=\"278465817\" style=\"display:none\">\n",
    "                              <i class=\"icon icon-collection icon-medium icon-white\"></i>\n",
    "                        </a>\n",
    "                        <a data-item-id=\"278465817\" data-type=\"entry\" data-message=\"Ho%20proprio%20dovuto%20condividere%20questa%20immagine%20%40WeHeartIt\" class=\"js-share-button col\" title=\"Condividi\" tabindex=\"-1\" href=\"/entry/278465817\"><i class=\"icon icon-share icon-medium icon-white\"></i>\n",
    "                        </a>\n",
    "                        <a href=\"/postcards/278465817\" class=\"js-postcard-button col\" data-entry-id=\"278465817\">\n",
    "                            <i class=\"icon icon-messages icon-medium icon-white\"></i>\n",
    "                        </a>\n",
    "                    </div>\n",
    "                </div>\n",
    "            </div>\n",
    "        </div>\n",
    "    </div>\n",
    "</div>\n",
    "```\n",
    "La struttura di ogni singolo elemento è piuttosto complicata, ma procediamo per piccoli passi. Il nostro primo obiettivo è cercare nella pagina tutti gli elementi che contengono le immagini.\n",
    "\n",
    "Per completare il primo obiettivo possiamo sfruttare il modulo BeautifulSoup, il quale permette di ricerca tag HTML specificando, per esempio, l'attributo da cercare.\n",
    "\n",
    "Nel nostro caso possiamo sfruttare l'integrazione del codice HTML con un foglio di stile CSS. In particolare l'applicazione di un determinato stile ad un tag HTML è possibile grazie alla presenza di attributi identificatori come **class** o **id**. Nel nostro caso ogni elemento contenente un'immagine è un tag **div** il cui attributo **class** è uguale a **entry grid-item**.\n",
    "\n",
    "A tal fine possiamo utilizzare il metodo **findAll** dell'oggetto BS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r = whi_session.get('https://weheartit.com/popular_images/2018/02/14')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_popular_page = BeautifulSoup(r.text.replace('\\n',''),'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "div_immagini = most_popular_page.findAll('div',{'class':'entry grid-item'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for e in div_immagini:\n",
    "    print(str(e.get_text()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il metodo **get_text()** rimuove tutti i tag dal documento e restituisce una stringa che contiene solo il testo. Elementi come link (a), paragrafi (p) vengono rimossi.\n",
    "\n",
    "BS rende a disposizione due metodi di ricerca **find** e **find_all**. Entrambi i metodi accettano gli stessi parametri: tag, attributes, recursive, text, limit e keywords.\n",
    "- **tag** accetta un tag o una lista di tag HTML (stringhe)\n",
    "- **attributes** accetta una dict di attributi e restituisce i tag che contengono uno qualsiasi degli attributi (OR)\n",
    "- **recursive** se False limita la ricerca ai tag a profondità 1 nell'albero XML\n",
    "- **text** la ricerca viene effettuata sul testo contenuto dai tag\n",
    "- **limit** limita il numero di elementi restituiti. Funziona solo con findAll\n",
    "- **keyword** permette di selezionare tags che contengono un determinato attributo (AND)\n",
    "\n",
    "N.b. Attenzione all'utilizzo di class come keyword in quanto la parola _class_ è riservata da Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_popular_page.findAll('div',class='entry grid-item',limit=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str(most_popular_page.findAll('div',class_='entry grid-item',limit=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una volta ottenuto l'elemento ricercato possiamo 'navigare' il suo albero HTML per ottenere gli elementi che contengono le informazioni richieste.\n",
    "\n",
    "Nel nostro caso l'albero è il seguente:\n",
    "<img src='tree_immagine.jpg'>\n",
    "\n",
    "Per accedere ai nodi del nostro albero possiamo sfruttare la sintassi vista in precedenza tuttavia si deve precisare che la sintassi vista viene utilizzata per indicare un qualsiasi **discendente** del tag corrente = un qualsiasi nodo nel sottoalbero la cui radice è il tag corrente.\n",
    "\n",
    "Se voglio accedere solo ai figli (discendenti diretti) di un nodo utilizzo l'attributo **children**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_image = most_popular_page.find('div',class_='entry grid-item')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selezioniamo il figlio della radice _div_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str(list(first_image.children)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Posso ottenere i 'fratelli di un tag' utilizzando l'attributo **next_siblings**, il quale restituisce un iteratore sugli elementi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for bro in first_image.div.div.a.next_siblings:\n",
    "    print('---',str(bro),'---')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cerchiamo ora di estrarre da ogni immagine il link all'immagine e l'utente che ha pubblicato l'immagine.\n",
    "\n",
    "Le informazioni dell'utente sono contenute in **a class=\"avatar-container avatar-small\"**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for e in div_immagini:\n",
    "    print(e.find('a',class_ = 'avatar-container').attrs['href'][1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mentre il link all'immagine è associato al tag **a class=\"js-entry-detail-link\"**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for e in div_immagini:\n",
    "    print('https://weheartit.com'+e.find('a',class_ = 'js-entry-detail-link').attrs['href'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Come ulteriore passo possiamo scaricare la thumbnail associato al profile che ha postato l'immagine. L'URL è associato all'attributo _src_ del tag _img_ contenuto in  **a class = avatar-container**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from io import BytesIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for e in div_immagini:\n",
    "    url = e.find('a',class_='avatar-container').img.attrs['src']\n",
    "    print(url)\n",
    "    filename = url.split('/')[4]\n",
    "    r = whi_session.get(url)\n",
    "    i = Image.open(BytesIO(r.content))\n",
    "    i.save('thumbnails/'+filename+'.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se apriamo nel nostro browser la pagina delle immagini più popolari possiamo notare che il caricamento delle immagini è dinamico. Quando si raggiunge il termine della pagina vengono caricate delle nuove immagini. Questo tipo di metodo è ormai utilizzato nella maggior parte delle piattaforme sociali (timeline di Facebook, Twitter, ...) in quanto evita di caricare immagini che molto probabilmente non verranno mai guardate. Il meccanismo di caricamento dinamico si riduce ai seguenti passi:\n",
    "1. L'utente arriva alla fine della pagina generando un evento 'finePagina'\n",
    "2. L'evento viene catturato da Javascript e risveglia una funzione che si occupa di ottenere le nuove immagini\n",
    "3. Viene inviato una richiesta HTTP al web server per chiedere le nuove immagini\n",
    "4. La funzione di caricamento modifica il codice HTML e inserisce i nuovi elementi\n",
    "\n",
    "Il passo fondamentale per implementare lo scraper è il numero di 3. Se riuscissimo ad intercettare la richiesta inviata potremmo replicare la stessa richiesta all'interno del nostro server.\n",
    "\n",
    "Per intercettare la richiesta possiamo utilizzare il developer tools di Chrome (CRTL+SHIFT+I) e aprire il tab 'Network'.\n",
    "\n",
    "Dopo aver analizzato le varie richieste si scopre che la richiesta per ottenere un nuovo insieme di immagini è la seguente:\n",
    "\n",
    "http://weheartit.com/popular_images/2018/02/14?scrolling=true&page=2&before=278465601\n",
    "\n",
    "I parametri fondamentali sono page e before:\n",
    "**page** rappresenta la pagina da richiedere\n",
    "**before** rappresenta l'id dell'ultima immagine attualmente visualizzata.\n",
    "\n",
    "Il problema diventa, quindi, estrarre i parametri dalla pagina/informazioni che abbiamo a disposizione. Per quanto riguarda _page_, il valore accettato è incrementale (+1 ad ogni nuova richiesta) ed è limitato dal numero massimo di pagine. Come possiamo ottenere questa informazione.\n",
    "\n",
    "Nel codice HTML della prima pagina troviamo il seguente tag con attributo **data-infinite-scroll-count**. L'attributo definisce il numero massimo di pagine.\n",
    "``` html\n",
    "<div data-ad-placeholder-url=\"http://weheartit.com/entry/placeholder?options=%7B%22context%22%3A%7B%22type%22%3A%22popular_images%22%7D%7D\" data-infinite-scroll-count=\"294\" data-infinite-scroll-page=\"1\" data-infinite-scroll-url=\"http://weheartit.com/popular_images/2017/02/16\" id=\"content\">\n",
    "```\n",
    "\n",
    "Come possiamo estrarre questa informazione...\n",
    "\n",
    "Otteniamo il div"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "div_pagina = most_popular_page.find('div',{'id':'content'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estriamo il valore associato all'attributo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_pages = int(div_pagina.attrs['data-infinite-scroll-count'])\n",
    "print(max_pages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per quanto riguarda il secondo parametro, dobbiamo estrarre l'id delle immagini. Il metodo è molto simile a quanto abbiamo già visto in precedenza."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for e in div_immagini:\n",
    "    u = e.find('a',class_ = 'js-entry-detail-link').attrs['href']\n",
    "    print(u)\n",
    "    before = u.split('?')[0][len('/entry/'):]\n",
    "print(before)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ora siamo in grado di estrarre tutte le informazioni da tutte le immagini più popolari:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "whi_session.post('https://weheartit.com/login/authenticate',data=parametri,allow_redirects=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_popular_page = BeautifulSoup(whi_session.get('https://weheartit.com/popular_images/2018/02/14').text,'lxml')\n",
    "most_popular_images = []\n",
    "max_pages = int(most_popular_page.find('div',{'id':'content'}).attrs['data-infinite-scroll-count'])\n",
    "for e in most_popular_page.findAll('div',{'class':'entry grid-item'}):\n",
    "    username = e.find('a',class_ = 'avatar-container').attrs['href'][1:]\n",
    "    url = e.find('a',class_ = 'js-entry-detail-link').attrs['href']\n",
    "    url_thumb = e.find('a',class_='avatar-container').img.attrs['src']\n",
    "    filename = url_thumb.split('/')[4]\n",
    "    r = whi_session.get(url_thumb)\n",
    "    i = Image.open(BytesIO(r.content))\n",
    "    i.save('thumbnails/'+filename+'.jpg')\n",
    "    before = u.split('?')[0][len('/entry/'):]\n",
    "    most_popular_images.append({'username':username,'url':url})\n",
    "for k in range(2,16):\n",
    "    if k % 15 == 0:\n",
    "        time.sleep(15)\n",
    "    most_popular_page = BeautifulSoup(whi_session.get('http://weheartit.com/popular_images/2018/02/14?scrolling=true&page='+str(k)+'&before='+before).text,'lxml')\n",
    "    for e in most_popular_page.findAll('div',{'class':'entry grid-item'}):\n",
    "        try:\n",
    "            username = e.find('a',class_ = 'avatar-container').attrs['href'][1:]\n",
    "        except AttributeError:\n",
    "            pass\n",
    "        url = e.find('a',class_ = 'js-entry-detail-link').attrs['href']\n",
    "        try:\n",
    "            url_thumb = e.find('a',class_='avatar-container').img.attrs['src']\n",
    "            filename = url_thumb.split('/')[4]\n",
    "            extension = url_thumb.split('?')[0][-3:]\n",
    "            r = whi_session.get(url_thumb)\n",
    "            i = Image.open(BytesIO(r.content))\n",
    "            i.save('thumbnails/'+filename+'.'+extension)\n",
    "        except AttributeError:\n",
    "            pass\n",
    "        before = u.split('?')[0][len('/entry/'):]\n",
    "        most_popular_images.append({'username':username,'url':url})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Costruzione del grafo dei follower in WHI\n",
    "\n",
    "Per rendere il codice minimamente modulare implementeremo una funzione get_friend(profile_name) che restituisce i primi venti profili che l'utente *profile_name* segue in WHI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_friends(profile_name):\n",
    "    lista_amici = []\n",
    "    url = 'http://weheartit.com/'+profile_name+'/contacts'\n",
    "    profile_friend_page = requests.get(url)\n",
    "    friend_soup = BeautifulSoup(profile_friend_page.content,'lxml')\n",
    "    div_friends = friend_soup.findAll('div',class_='js-user-info')\n",
    "    for friend in div_friends:\n",
    "        friend_profile = friend.find('a',class_='avatar-container').attrs['href'][1:]\n",
    "        lista_amici.append(friend_profile)\n",
    "    return lista_amici"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una volta definita la funzione di estrazione della lista degli amici possiamo implementare una visita in profondità del grafo.\n",
    "Nella seguente implementazione esploriamo i nodi a distanza due hop dalla sorgente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seeds = ['somenilab']\n",
    "#whi_graph = nx.DiGraph() --> questa riga verrà utilizzata una volta introdotta la libreria NetworkX\n",
    "file_edge_list = open('edge_list_whi.txt','w')\n",
    "nodi_visitati = set()\n",
    "queue = []\n",
    "for e in seeds:\n",
    "    queue.append((e,0))\n",
    "while queue:\n",
    "    nodo, distanza = queue.pop(0)\n",
    "    print(nodo,distanza)\n",
    "    if (nodo not in nodi_visitati) and distanza < 3:\n",
    "        lista_amici = get_friends(nodo)\n",
    "        print(len(lista_amici))\n",
    "        time.sleep(2)\n",
    "        for a in lista_amici:\n",
    "            #whi_graph.add_edge(nodo,a)\n",
    "            file_edge_list.write(nodo+','+a+'\\n')\n",
    "            queue.append((a,distanza+1))\n",
    "        nodi_visitati.add(nodo)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
